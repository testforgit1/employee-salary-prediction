import streamlit as st
import pandas as pd
import joblib
import numpy as np

# Load the trained model and preprocessing objects
model = joblib.load("best_model.pkl")
scaler = joblib.load("scaler.pkl")
encoded_columns = joblib.load("encoded_columns.pkl")

# Set page configuration
st.set_page_config(page_title="Employee Salary Classification", page_icon="ðŸ’¼", layout="centered")

st.title("ðŸ’¼ Employee Salary Classification App")
st.markdown("Predict whether an individual's income exceeds $50,000 annually based on demographic and employment features.")

# Define categorical feature options based on notebook's value_counts() and UCI dataset
workclass_options = ['Private', 'Self-emp-not-inc', 'Local-gov', 'NotListed', 'State-gov', 'Self-emp-inc', 'Federal-gov']
marital_status_options = ['Married-civ-spouse', 'Never-married', 'Divorced', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse']
occupation_options = ['Prof-specialty', 'Craft-repair', 'Exec-managerial', 'Adm-clerical', 'Sales', 'Other-service', 
                     'Machine-op-inspct', 'Others', 'Transport-moving', 'Handlers-cleaners', 'Farming-fishing', 
                     'Tech-support', 'Protective-serv', 'Priv-house-serv', 'Armed-Forces']
relationship_options = ['Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Wife', 'Other-relative']
race_options = ['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other']
gender_options = ['Male', 'Female']
native_country_options = ['United-States', 'Mexico', 'Philippines', 'Germany', 'Canada', 'Puerto-Rico', 'El-Salvador', 
                         'India', 'Cuba', 'England', 'Jamaica', 'South', 'China', 'Italy', 'Dominican-Republic', 
                         'Vietnam', 'Guatemala', 'Japan', 'Poland', 'Columbia', 'Taiwan', 'Haiti', 'Iran', 'Portugal', 
                         'Nicaragua', 'Peru', 'France', 'Greece', 'Ecuador', 'Ireland', 'Hong', 'Cambodia', 
                         'Trinadad&Tobago', 'Laos', 'Thailand', 'Yugoslavia', 'Outlying-US(Guam-USVI-etc)', 
                         'Hungary', 'Honduras', 'Scotland']

# Sidebar inputs
st.sidebar.header("Input Individual Details")
age = st.sidebar.slider("Age", 17, 90, 30)
fnlwgt = st.sidebar.slider("Final Weight (fnlwgt)", 10000, 1500000, 200000)
educational_num = st.sidebar.slider("Educational Number (1-16)", 1, 16, 10)
capital_gain = st.sidebar.slider("Capital Gain", 0, 100000, 0)
capital_loss = st.sidebar.slider("Capital Loss", 0, 5000, 0)
hours_per_week = st.sidebar.slider("Hours per Week", 1, 100, 40)
workclass = st.sidebar.selectbox("Workclass", workclass_options)
marital_status = st.sidebar.selectbox("Marital Status", marital_status_options)
occupation = st.sidebar.selectbox("Occupation", occupation_options)
relationship = st.sidebar.selectbox("Relationship", relationship_options)
race = st.sidebar.selectbox("Race", race_options)
gender = st.sidebar.selectbox("Gender", gender_options)
native_country = st.sidebar.selectbox("Native Country", native_country_options)

# Build input DataFrame
input_df = pd.DataFrame({
    'age': [age],
    'fnlwgt': [fnlwgt],
    'educational-num': [educational_num],
    'capital-gain': [capital_gain],
    'capital-loss': [capital_loss],
    'hours-per-week': [hours_per_week],
    'workclass': [workclass],
    'marital-status': [marital_status],
    'occupation': [occupation],
    'relationship': [relationship],
    'race': [race],
    'gender': [gender],
    'native-country': [native_country]
})

# Preprocess input data
def preprocess_input(input_df):
    # One-hot encode categorical features
    categorical_cols = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']
    input_encoded = pd.get_dummies(input_df, columns=categorical_cols, drop_first=True)
    
    # Align with model's expected columns
    input_encoded = input_encoded.reindex(columns=encoded_columns, fill_value=0)
    
    # Scale numerical features
    numerical_cols = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']
    input_encoded[numerical_cols] = scaler.transform(input_encoded[numerical_cols])
    
    return input_encoded

# Display input data
st.write("### ðŸ”Ž Input Data")
st.write(input_df)

# Single prediction
if st.button("Predict Salary Class"):
    input_processed = preprocess_input(input_df)
    prediction = model.predict(input_processed)[0]
    prediction_proba = model.predict_proba(input_processed)[0]
    result = ">50K" if prediction == 1 else "<=50K"
    st.success(f"âœ… Predicted Income: {result}")
    st.write(f"Probability (<=50K, >50K): {prediction_proba[0]:.2f}, {prediction_proba[1]:.2f}")

# Batch prediction
st.markdown("---")
st.markdown("#### ðŸ“‚ Batch Prediction")
st.markdown("Upload a CSV file with columns: age, fnlwgt, educational-num, capital-gain, capital-loss, hours-per-week, workclass, marital-status, occupation, relationship, race, gender, native-country")
uploaded_file = st.file_uploader("Upload a CSV file for batch prediction", type="csv")

if uploaded_file is not None:
    batch_data = pd.read_csv(uploaded_file)
    st.write("Uploaded data preview:", batch_data.head())
    batch_processed = preprocess_input(batch_data)
    batch_preds = model.predict(batch_processed)
    batch_data['PredictedIncome'] = ['>50K' if pred == 1 else '<=50K' for pred in batch_preds]
    st.write("âœ… Predictions:")
    st.write(batch_data[['PredictedIncome']].head())
    csv = batch_data.to_csv(index=False).encode('utf-8')
    st.download_button("Download Predictions CSV", csv, file_name='predicted_income.csv', mime='text/csv')

st.markdown("---")
st.markdown("Built with Streamlit. Model trained on UCI Adult Income dataset.")

## Deployment
To deploy the app on Streamlit Community Cloud:
1. Push the repository to GitHub.
2. Create a `requirements.txt` with `streamlit`, `pandas`, `numpy`, `scikit-learn`.
3. Connect the repository to Streamlit Community Cloud and deploy `app.py`.
